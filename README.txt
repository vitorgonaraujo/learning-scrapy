
ğŸ•·ï¸ Web Crawler com Scrapy

Este Ã© um projeto simples de crawler feito em Python usando o Scrapy.
Criei para me desafiar a entender na prÃ¡tica como o Scrapy funciona.

ğŸ“Œ Tecnologias usadas
- Python
- Scrapy
- Pipenv (para gerenciar o ambiente virtual e as dependÃªncias)

ğŸš€ Como rodar
1. Clone o repositÃ³rio:
   git clone https://github.com/vitorgonaraujo/learning-scrapy.git
   cd seu-repo

2. Instale o Pipenv (se ainda nÃ£o tiver):
   pip install pipenv

3. Instale as dependÃªncias:
   pipenv install

4. Ative o ambiente virtual:
   pipenv shell

5. Execute o crawler:
   scrapy crawl bookspider

âš™ï¸ O que faz
- Acessa o site "https://books.toscrape.com"
- Coleta imagem, tÃ­tulo, preÃ§o e etc.
- Salva os dados em um arquivo chamado booksdata.json

ğŸ“š Objetivo
Projeto feito para aprender os fundamentos do Scrapy e praticar Python.
